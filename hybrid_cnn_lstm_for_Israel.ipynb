{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Importing Dependencies\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Import the data\n",
        "data = pd.read_csv('Combined Customers Data - Sheet1.csv')\n",
        "\n",
        "# Separate the labels (fraudulent or normal) from the input features\n",
        "labels = data['FLAG']\n",
        "input_features = data.drop(columns=['CUSTOMER', 'FLAG'])\n",
        "\n",
        "# Replace non-numeric or null values with NaN in input features\n",
        "input_features = input_features.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Replace NaN values with zero\n",
        "input_features = input_features.fillna(0)\n",
        "\n",
        "# Stratified splitting of the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(input_features, labels, test_size=0.3, stratify=labels, random_state=42)\n",
        "\n",
        "# Reshape the input data for CNN (assuming each month represents an image)\n",
        "num_features = X_train.shape[1]\n",
        "X_train_cnn = np.array(X_train).reshape(-1, num_features, 1)\n",
        "X_test_cnn = np.array(X_test).reshape(-1, num_features, 1)\n",
        "\n",
        "# Define the CNN model\n",
        "def create_cnn_model():\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv1D(32, 3, activation='relu', input_shape=(num_features, 1), padding='same'))\n",
        "    model.add(layers.MaxPooling1D(1))\n",
        "    model.add(layers.Conv1D(64, 3, activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling1D(1))\n",
        "    model.add(layers.Conv1D(128, 3, activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling1D(1))\n",
        "    model.add(layers.Conv1D(256, 3, activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling1D(1))\n",
        "    model.add(layers.Conv1D(512, 3, activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling1D(1))\n",
        "    model.add(layers.Flatten())\n",
        "    return model\n",
        "\n",
        "# Create the CNN model\n",
        "cnn_model = create_cnn_model()\n",
        "\n",
        "# Define the LSTM model\n",
        "def create_lstm_model():\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.LSTM(128, input_shape=(num_features, 1)))\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "# Create the LSTM model\n",
        "lstm_model = create_lstm_model()\n",
        "time_steps = 1  # Each month considered as a single time step\n",
        "\n",
        "# Combine the CNN and LSTM models\n",
        "combined_model = models.Sequential()\n",
        "combined_model.add(layers.TimeDistributed(cnn_model, input_shape=(time_steps, num_features, 1)))\n",
        "combined_model.add(layers.LSTM(64))\n",
        "combined_model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the combined model\n",
        "combined_model.compile(optimizer='adam',\n",
        "                       loss='binary_crossentropy',\n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "combined_model.summary()\n",
        "\n",
        "# Reshape the input data for LSTM\n",
        "time_steps = 1  # Each month considered as a single time step\n",
        "X_train_lstm = np.array(X_train).reshape(-1, time_steps, num_features)\n",
        "X_test_lstm = np.array(X_test).reshape(-1, time_steps, num_features)\n",
        "\n",
        "# Train the combined model using the training data\n",
        "history = combined_model.fit(X_train_lstm, y_train, epochs=18, batch_size=16)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = combined_model.evaluate(X_test_lstm, y_test, verbose=0)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "# Plot the accuracy and loss over epochs\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6Dkp14pQ9dfS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}